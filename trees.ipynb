{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xadc645efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Sample code number            -0.080378\n",
       "Clump_Thickness                0.716509\n",
       "Uniformity_of_Cell_Size        0.817772\n",
       "Uniformity_of_Cell_Shape       0.818794\n",
       "Marginal_Adhesion              0.696605\n",
       "Single_Epithelial_Cell_Size    0.682618\n",
       "Bare_Nuclei                    0.706209\n",
       "Bland_Chromatin                0.756732\n",
       "Normal_Nucleoli                0.712067\n",
       "Mitoses                        0.423008\n",
       "label                          1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data')\n",
    "data.columns=['Sample code number','Clump_Thickness','Uniformity_of_Cell_Size','Uniformity_of_Cell_Shape','Marginal_Adhesion','Single_Epithelial_Cell_Size','Bare_Nuclei','Bland_Chromatin','Normal_Nucleoli','Mitoses','label']\n",
    "data=data.replace('?',15)\n",
    "data['Bare_Nuclei']=data['Bare_Nuclei'].astype(dtype='i')\n",
    "data.corr()['label']\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.countplot('label',data=data)\n",
    "plt.savefig('f:/breast_cancer_count.png')\n",
    "plt.show()\n",
    "data.corr()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop('Sample code number',axis=1,inplace=True)# due to no correlation we need to drop thid column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tr_te_split(dtf, t_size):\n",
    "    t_size = int(t_size * dtf.shape[0]) # calculating the testsize according to the length of data\n",
    "    indexes = dtf.index.tolist() # we will take the index of the data-frame to randomize\n",
    "    t_index = r.sample(population=indexes, k=t_size) #using the random randomizing the indexes\n",
    "    test_df = dtf.loc[t_index]   #seprating the random test_data based on the random indexes obtained from t_index\n",
    "    train_df = dtf.drop(t_index)  # in train data we need to remove the t_index as it is in the test data\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((698, 10),\n",
       " (559, 10),\n",
       " (139, 10),\n",
       " Int64Index([292, 689,  54, 587, 496,  20, 417, 299,   3, 592,\n",
       "             ...\n",
       "             328, 608, 157, 688, 221, 218, 300, 551, 404, 316],\n",
       "            dtype='int64', length=139))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = tr_te_split(data, t_size=0.2)\n",
    "data.shape,train.shape,test.shape,test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def type_of_cols(sf,data):\n",
    "        # if the availabe no of unique values of a column is greater than 5 then it can be classified as continues\n",
    "        #else as categorial\n",
    "        col_type_and_name=[]\n",
    "        col_type=[]\n",
    "        no_of_unique=5\n",
    "        for col in data.columns[:-1]:\n",
    "            no_of_col_unique= data[col].nunique()\n",
    "            if data[col].dtypes==object or no_of_col_unique<no_of_unique:\n",
    "                col_type_and_name.append((col,\"categorical\"))\n",
    "                col_type.append(\"categorical\")\n",
    "            else:\n",
    "                col_type_and_name.append((col,\"continuous\"))\n",
    "                col_type.append(\"continuous\")\n",
    "        return col_type\n",
    "    def get_splits(sf,data):\n",
    "        splits = {} # dict to store the possible splits of our data based on either categorial or continues data\n",
    "        feature_type=sf.type_of_cols(data) # get the type of data of each column of feature set\n",
    "        for column_index in range(data.shape[1]-1):          # excluding the last column which is the label\n",
    "            values = data.iloc[:, column_index] # accessing the all the column value based on index nor the column name\n",
    "            unique_values = np.unique(values) #fetch the unique values of the respective column\n",
    "            type_of_feature = feature_type[column_index] # get data type of column i.e categorial or continues\n",
    "            if type_of_feature == \"continuous\":\n",
    "                splits[column_index] = []\n",
    "                for index in range(len(unique_values)):\n",
    "                    if index != 0:\n",
    "                        current_value = unique_values[index]\n",
    "                        previous_value = unique_values[index - 1]\n",
    "                        split = (current_value + previous_value) / 2\n",
    "                        splits[column_index].append(split)\n",
    "            # feature is categorical(there need to be at least 2 unique values, otherwise in the \n",
    "            #split_data function data_below would contain all data points and data_above would be empty)\n",
    "            elif len(unique_values) > 1:\n",
    "                splits[column_index] = unique_values\n",
    "        return splits\n",
    "    def split_data(sf,data, column, value):\n",
    "        #based on to column's data type we will destribute the data into two portion's \n",
    "        feature_type=sf.type_of_cols(data)\n",
    "        split_values = data.iloc[:,column]\n",
    "        type_of_feature = feature_type[column]\n",
    "        if type_of_feature == \"continuous\": # in case of continues data we will use greater or lesser than operator\n",
    "            left = data[split_values <= value]\n",
    "            right = data[split_values >  value]\n",
    "        else:# in case of categorial data will use logical equal or not equal operator\n",
    "            left = data[split_values == value]\n",
    "            right = data[split_values != value]\n",
    "        return left,right\n",
    "\n",
    "    def entropy(sf,data):#we are calculating the entropy of class \n",
    "        prob=list(dict(data.iloc[:, -1].value_counts(normalize=True)).values())\n",
    "        entropy = sum(prob* -np.log2(prob))    \n",
    "        return entropy\n",
    "\n",
    "    def entropy_data(sf,left,right):    \n",
    "        n = len(left) + len(right)\n",
    "        p_left = len(left) / n\n",
    "        p_right = len(right) / n\n",
    "        entropy_ =  (p_left * sf.entropy(left)+ p_right *sf.entropy(right))\n",
    "        return entropy_\n",
    "    \n",
    "    def best_split(sf,data,splits):\n",
    "        entropy = 9999 #we assume a dummy entropy to compare with obtained entropy for the first time \n",
    "        for col in splits: # iterating over the splits obtained by the get_split method for each columns\n",
    "            for val in splits[col]: # iterating over the splits of a indivisual columns\n",
    "                left, right = sf.split_data(data, column=col, value=val)# spliting the data according to obtained split(val) of a column\n",
    "                current_entropy = sf.entropy_data(left,right) #calculating the entropy of a column\n",
    "                if current_entropy <= entropy: # if obtained entropy is lesser than assumed entropy \n",
    "                    entropy = current_entropy #then assume the obtained entropy as best entropy\n",
    "                    best_column = col # the current column can be termend as best column and the split too\n",
    "                    best_split = val\n",
    "        return best_column, best_split\n",
    "    \n",
    "    def tree_builder(sf,df, counter=0, min_samples=2, max_depth=5):\n",
    "        from collections import Counter\n",
    "        # data preparations\n",
    "        column=df.columns #store the column name\n",
    "        feature_type=sf.type_of_cols(df) # store the column value type i.e categorial/continues \n",
    "        data = df\n",
    "        # base cases\n",
    "        if (df.iloc[:,-1].nunique()==1) or (len(data) < min_samples) or (counter == max_depth):\n",
    "            classes= Counter(data.iloc[:,-1]).most_common(1)[0][0]\n",
    "            return classes\n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "            splits = sf.get_splits(data)#calculating the splits of each columns\n",
    "            split_column, split_value = sf.best_split(data,splits) #getting the best column and split value\n",
    "            left, right = sf.split_data(data, split_column, split_value) # based on the above split and column divide the data \n",
    "            # determine question\n",
    "            feature_name = column[split_column] #pick the column name\n",
    "            type_of_feature = feature_type[split_column]\n",
    "            if type_of_feature == \"continuous\":\n",
    "                question = \"{} <= {}\".format(feature_name, split_value) # assign the column name ,type of operator to be used and the split value            \n",
    "            # feature is categorical\n",
    "            else:\n",
    "                question = \"{} = {}\".format(feature_name, split_value)\n",
    "            # instantiate sub-tree\n",
    "            mytree = {question: []}\n",
    "            # find answers (recursion)\n",
    "            ans_yes = sf.tree_builder(left, counter, min_samples, max_depth) # left leave is for yes where tree traversal stops\n",
    "            ans_no = sf.tree_builder(right, counter, min_samples, max_depth) # right leave needs few more nodes\n",
    "            # If the answers are the same, then there is no point in asking the question.\n",
    "            # This could happen when the data is classified even though it is not pure\n",
    "            # yet (min_samples or max_depth base case).\n",
    "            if ans_yes == ans_no:\n",
    "                mytree = ans_yes\n",
    "            else:\n",
    "                mytree[question].append(ans_yes)\n",
    "                mytree[question].append(ans_no)\n",
    "        \n",
    "            return mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Uniformity_of_Cell_Size <= 2.5': [{'Clump_Thickness <= 6.5': [{'Normal_Nucleoli <= 4.5': [2,\n",
       "      {'Bland_Chromatin = 7': [4, 2]}]},\n",
       "    {'Bare_Nuclei <= 2.0': [2, 4]}]},\n",
       "  {'Uniformity_of_Cell_Size <= 4.5': [{'Bare_Nuclei <= 6.0': [{'Normal_Nucleoli <= 1.5': [2,\n",
       "        {'Clump_Thickness <= 4.5': [2, 4]}]},\n",
       "      {'Bare_Nuclei <= 12.5': [4, 2]}]},\n",
       "    4]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg=Tree()\n",
    "tree=alg.tree_builder(train)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(Tree):\n",
    "    def fit(sf,train):\n",
    "        sf.tree=sf.tree_builder(train)\n",
    "        return sf.tree\n",
    "    def predict(sf,dx,tree):\n",
    "        root_node = list(tree.keys())[0] # fetch the root node's value i.e our dict keys which consits of column name,operator and split value \n",
    "        column,operator,split=root_node.split(\" \") # we have used the space as a seprator b/w the three data\n",
    "        if operator == \"<=\": # if the operator is lesser than or equal it means th column type is continues\n",
    "            \n",
    "            if dx[column] <= float(split):\n",
    "                result = tree[root_node][0]\n",
    "            else:\n",
    "                result = tree[root_node][1]\n",
    "        # if column  is categorical then we can use logical equal operator\n",
    "        else:\n",
    "            if str(dx[column]) == split:\n",
    "                result = tree[root_node][0]\n",
    "            else:\n",
    "                result = tree[root_node][1]\n",
    "        if type(result)!=dict: # if the result is dict then we have more nodes to be traversed\n",
    "            return result\n",
    "        # else recursively travers the entire tree for accurate results\n",
    "        else:\n",
    "            return sf.predict(dx,result)\n",
    "    def score(sf,x,y):\n",
    "        c=0 # we will pass a indivisual x into predict and compare the given y with the predicted y if both are equal then c will be incremented by 1 \n",
    "        for i in range(len(x)):\n",
    "            if sf.predict(x.iloc[i],sf.tree)==y.iloc[i]:\n",
    "                c+=1\n",
    "        return c/len(x) # finally resultant is correct prediction by the total len of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Uniformity_of_Cell_Size <= 2.5': [{'Clump_Thickness <= 6.5': [{'Normal_Nucleoli <= 4.5': [2,\n",
       "      {'Bland_Chromatin = 7': [4, 2]}]},\n",
       "    {'Bare_Nuclei <= 2.0': [2, 4]}]},\n",
       "  {'Uniformity_of_Cell_Size <= 4.5': [{'Bare_Nuclei <= 6.0': [{'Normal_Nucleoli <= 1.5': [2,\n",
       "        {'Clump_Thickness <= 4.5': [2, 4]}]},\n",
       "      {'Bare_Nuclei <= 12.5': [4, 2]}]},\n",
       "    4]}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo=DecisionTree()\n",
    "algo.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.920863309352518"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=test.drop('label',axis=1)\n",
    "test_y=test['label']\n",
    "algo.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RTree:\n",
    "    def type_of_cols(sf,data):\n",
    "        # if the availabe no of unique values of a column is greater than 5 then it can be classified as continues\n",
    "        #else as categorial\n",
    "        col_type_and_name=[]\n",
    "        col_type=[]\n",
    "        no_of_unique=5\n",
    "        for col in data.columns[:-1]:\n",
    "            no_of_col_unique= data[col].nunique()\n",
    "            if data[col].dtypes==object or no_of_col_unique<no_of_unique:\n",
    "                col_type_and_name.append((col,\"categorical\"))\n",
    "                col_type.append(\"categorical\")\n",
    "            else:\n",
    "                col_type_and_name.append((col,\"continuous\"))\n",
    "                col_type.append(\"continuous\")\n",
    "        return col_type\n",
    "    def get_splits(sf,data,rnd):\n",
    "        splits = {}\n",
    "        col = data.shape[1]\n",
    "        col= list(range(col - 1))    # leaving the label\n",
    "    \n",
    "        if rnd and rnd <= len(col):\n",
    "            col = r.sample(population=col, k=rnd)\n",
    "        for c in col:  \n",
    "            val = data.iloc[:, c]\n",
    "            u_val = np.unique(val)\n",
    "        \n",
    "            splits[c] = u_val\n",
    "        return splits\n",
    "    def split_data(sf,data, column, value):\n",
    "        #based on to column's data type we will destribute the data into two portion's \n",
    "        feature_type=sf.type_of_cols(data)\n",
    "        split_values = data.iloc[:,column]\n",
    "        type_of_feature = feature_type[column]\n",
    "        if type_of_feature == \"continuous\": # in case of continues data we will use greater or lesser than operator\n",
    "            left = data[split_values <= value]\n",
    "            right = data[split_values >  value]\n",
    "        else:# in case of categorial data will use logical equal or not equal operator\n",
    "            left = data[split_values == value]\n",
    "            right = data[split_values != value]\n",
    "        return left,right\n",
    "\n",
    "    def entropy(sf,data):#we are calculating the entropy of class \n",
    "        prob=list(dict(data.iloc[:, -1].value_counts(normalize=True)).values())\n",
    "        entropy = sum(prob* -np.log2(prob))    \n",
    "        return entropy\n",
    "\n",
    "    def entropy_data(sf,left,right):    \n",
    "        n = len(left) + len(right)\n",
    "        p_left = len(left) / n\n",
    "        p_right = len(right) / n\n",
    "        entropy_ =  (p_left * sf.entropy(left)+ p_right *sf.entropy(right))\n",
    "        return entropy_\n",
    "    \n",
    "    def best_split(sf,data,splits):\n",
    "        entropy = 9999 #we assume a dummy entropy to compare with obtained entropy for the first time \n",
    "        for col in splits: # iterating over the splits obtained by the get_split method for each columns\n",
    "            for val in splits[col]: # iterating over the splits of a indivisual columns\n",
    "                left, right = sf.split_data(data, column=col, value=val)# spliting the data according to obtained split(val) of a column\n",
    "                current_entropy = sf.entropy_data(left,right) #calculating the entropy of a column\n",
    "                if current_entropy <= entropy: # if obtained entropy is lesser than assumed entropy \n",
    "                    entropy = current_entropy #then assume the obtained entropy as best entropy\n",
    "                    best_column = col # the current column can be termend as best column and the split too\n",
    "                    best_split = val\n",
    "        return best_column, best_split\n",
    "    \n",
    "    def tree_builder(sf,df, counter=0, min_samples=2, depth=5,rnd=2):\n",
    "        from collections import Counter\n",
    "        # data preparations\n",
    "        column=df.columns #store the column name\n",
    "        feature_type=sf.type_of_cols(df) # store the column value type i.e categorial/continues \n",
    "        data = df\n",
    "        # base cases\n",
    "        if (df.iloc[:,-1].nunique()==1) or (len(data) < min_samples) or (counter == depth):\n",
    "            try:\n",
    "                classes= Counter(data.iloc[:,-1]).most_common(1)[0][0]\n",
    "                return classes\n",
    "            except:\n",
    "                return\n",
    "            \n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "            splits = sf.get_splits(data,rnd)#calculating the splits of each columns\n",
    "            split_column, split_value = sf.best_split(data,splits) #getting the best column and split value\n",
    "            left, right = sf.split_data(data, split_column, split_value) # based on the above split and column divide the data \n",
    "            # determine question\n",
    "            feature_name = column[split_column] #pick the column name\n",
    "            type_of_feature = feature_type[split_column]\n",
    "            if type_of_feature == \"continuous\":\n",
    "                question = \"{} <= {}\".format(feature_name, split_value) # assign the column name ,type of operator to be used and the split value            \n",
    "            # feature is categorical\n",
    "            else:\n",
    "                question = \"{} = {}\".format(feature_name, split_value)\n",
    "            # instantiate sub-tree\n",
    "            mytree = {question: []}\n",
    "            # find answers (recursion)\n",
    "            ans_yes = sf.tree_builder(left, counter, min_samples, depth,rnd) # left leave is for yes where tree traversal stops\n",
    "            ans_no = sf.tree_builder(right, counter, min_samples, depth,rnd) # right leave needs few more nodes\n",
    "            # If the answers are the same, then there is no point in asking the question.\n",
    "            # This could happen when the data is classified even though it is not pure\n",
    "            # yet (min_samples or max_depth base case).\n",
    "            if ans_yes == ans_no:\n",
    "                mytree = ans_yes\n",
    "            else:\n",
    "                mytree[question].append(ans_yes)\n",
    "                mytree[question].append(ans_no)\n",
    "        \n",
    "            return mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RForestClas(RTree,DecisionTree):\n",
    "    def bstrap(sf,tr, n_bstrap):\n",
    "        bstrap_indexes=np.random.randint(low=0, high=len(tr), size=n_bstrap)\n",
    "        data_bstrapped = tr.iloc[bstrap_indexes]\n",
    "        return data_bstrapped\n",
    "    def fit(sf,tr, number_of_trees, n_bstrap,depth):\n",
    "        sf.myfor = []\n",
    "        for i in range(number_of_trees):\n",
    "            data_bstrapped = sf.bstrap(tr, n_bstrap)\n",
    "            single_tree = sf.tree_builder(data_bstrapped)\n",
    "            sf.myfor.append(single_tree)\n",
    "        return sf.myfor\n",
    "\n",
    "    def r_predict(sf,ts):\n",
    "        data_predict = {}\n",
    "        for f in range(len(sf.myfor)):\n",
    "            prds = sf.predict(ts, sf.myfor[f])\n",
    "            data_predict[f] = prds\n",
    "        predicted= pd.DataFrame()\n",
    "        predicted[0]=data_predict.values()\n",
    "        r_f_predictions = predicted.mode(axis=0)[0]\n",
    "        return r_f_predictions\n",
    "    def score(sf,x,y):\n",
    "        c=0 # we will pass a indivisual x into predict and compare the given y with the predicted y if both are equal then c will be incremented by 1 \n",
    "        for i in range(len(x)):\n",
    "            res=dict(sf.r_predict(x.iloc[i]))\n",
    "            if res[0]==y.iloc[i]:\n",
    "                c+=1\n",
    "        return c/len(x) # finally resultant is correct prediction by the total len of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Normal_Nucleoli <= 2': [{'Clump_Thickness <= 6': [{'Bland_Chromatin <= 4': [{'Bare_Nuclei <= 8': [2,\n",
       "         {'Uniformity_of_Cell_Size = 1': [2, 4]}]},\n",
       "       {'Clump_Thickness <= 2': [2, {'Marginal_Adhesion <= 1': [2, 4]}]}]},\n",
       "     {'Marginal_Adhesion <= 3': [{'Bare_Nuclei <= 2': [{'Bland_Chromatin = 5': [4,\n",
       "           2]},\n",
       "         4]},\n",
       "       4]}]},\n",
       "   {'Bare_Nuclei <= 3': [{'Marginal_Adhesion <= 6': [{'Single_Epithelial_Cell_Size <= 2': [2,\n",
       "         {'Bare_Nuclei = 2': [4, 2]}]},\n",
       "       4]},\n",
       "     {'Marginal_Adhesion <= 6': [{'Bare_Nuclei <= 10': [4, 2]}, 4]}]}]},\n",
       " {'Uniformity_of_Cell_Shape <= 2': [{'Clump_Thickness <= 5': [{'Marginal_Adhesion <= 6': [2,\n",
       "       4]},\n",
       "     {'Bland_Chromatin <= 3': [{'Mitoses = 2': [4, 2]},\n",
       "       {'Single_Epithelial_Cell_Size <= 1': [2, 4]}]}]},\n",
       "   {'Bland_Chromatin <= 4': [{'Uniformity_of_Cell_Size <= 2': [{'Normal_Nucleoli = 3': [4,\n",
       "         2]},\n",
       "       {'Uniformity_of_Cell_Shape <= 7': [{'Bare_Nuclei <= 1': [2, 4]}, 4]}]},\n",
       "     {'Bare_Nuclei <= 1': [{'Uniformity_of_Cell_Shape = 3': [2, 4]}, 4]}]}]},\n",
       " {'Uniformity_of_Cell_Shape <= 3': [{'Bare_Nuclei <= 1': [2,\n",
       "     {'Bland_Chromatin <= 3': [{'Uniformity_of_Cell_Size <= 1': [2,\n",
       "         {'Marginal_Adhesion <= 1': [2, 4]}]},\n",
       "       {'Uniformity_of_Cell_Shape = 1': [{'Clump_Thickness = 10': [4, 2]},\n",
       "         4]}]}]},\n",
       "   {'Uniformity_of_Cell_Size <= 4': [{'Clump_Thickness <= 5': [{'Normal_Nucleoli <= 2': [{'Uniformity_of_Cell_Shape = 5': [4,\n",
       "           2]},\n",
       "         4]},\n",
       "       {'Bare_Nuclei <= 1': [2, 4]}]},\n",
       "     4]}]},\n",
       " {'Uniformity_of_Cell_Size <= 2': [{'Clump_Thickness <= 7': [{'Normal_Nucleoli <= 2': [2,\n",
       "       {'Bland_Chromatin <= 5': [{'Bare_Nuclei = 4': [4, 2]}, 4]}]},\n",
       "     4]},\n",
       "   {'Marginal_Adhesion <= 1': [{'Bare_Nuclei <= 1': [{'Mitoses = 3': [4, 2]},\n",
       "       {'Uniformity_of_Cell_Shape <= 3': [{'Single_Epithelial_Cell_Size = 3': [4,\n",
       "           2]},\n",
       "         4]}]},\n",
       "     {'Uniformity_of_Cell_Size <= 4': [{'Marginal_Adhesion <= 6': [{'Bare_Nuclei <= 1': [2,\n",
       "           4]},\n",
       "         4]},\n",
       "       4]}]}]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo1=RForestClas()\n",
    "algo1.fit(train, 4, 800, depth=4)\n",
    "algo1.score(test_x,test_y)\n",
    "algo1.myfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Normal_Nucleoli <= 2': [{'Clump_Thickness <= 6': [{'Bland_Chromatin <= 4': [{'Bare_Nuclei <= 8': [2, {'Uniformity_of_Cell_Size = 1': [2, 4]}]}, {'Clump_Thickness <= 2': [2, {'Marginal_Adhesion <= 1': [2, 4]}]}]}, {'Marginal_Adhesion <= 3': [{'Bare_Nuclei <= 2': [{'Bland_Chromatin = 5': [4, 2]}, 4]}, 4]}]}, {'Bare_Nuclei <= 3': [{'Marginal_Adhesion <= 6': [{'Single_Epithelial_Cell_Size <= 2': [2, {'Bare_Nuclei = 2': [4, 2]}]}, 4]}, {'Marginal_Adhesion <= 6': [{'Bare_Nuclei <= 10': [4, 2]}, 4]}]}]}\n",
      "Trees\n",
      "\n",
      "\n",
      "{'Uniformity_of_Cell_Shape <= 2': [{'Clump_Thickness <= 5': [{'Marginal_Adhesion <= 6': [2, 4]}, {'Bland_Chromatin <= 3': [{'Mitoses = 2': [4, 2]}, {'Single_Epithelial_Cell_Size <= 1': [2, 4]}]}]}, {'Bland_Chromatin <= 4': [{'Uniformity_of_Cell_Size <= 2': [{'Normal_Nucleoli = 3': [4, 2]}, {'Uniformity_of_Cell_Shape <= 7': [{'Bare_Nuclei <= 1': [2, 4]}, 4]}]}, {'Bare_Nuclei <= 1': [{'Uniformity_of_Cell_Shape = 3': [2, 4]}, 4]}]}]}\n",
      "Trees\n",
      "\n",
      "\n",
      "{'Uniformity_of_Cell_Shape <= 3': [{'Bare_Nuclei <= 1': [2, {'Bland_Chromatin <= 3': [{'Uniformity_of_Cell_Size <= 1': [2, {'Marginal_Adhesion <= 1': [2, 4]}]}, {'Uniformity_of_Cell_Shape = 1': [{'Clump_Thickness = 10': [4, 2]}, 4]}]}]}, {'Uniformity_of_Cell_Size <= 4': [{'Clump_Thickness <= 5': [{'Normal_Nucleoli <= 2': [{'Uniformity_of_Cell_Shape = 5': [4, 2]}, 4]}, {'Bare_Nuclei <= 1': [2, 4]}]}, 4]}]}\n",
      "Trees\n",
      "\n",
      "\n",
      "{'Uniformity_of_Cell_Size <= 2': [{'Clump_Thickness <= 7': [{'Normal_Nucleoli <= 2': [2, {'Bland_Chromatin <= 5': [{'Bare_Nuclei = 4': [4, 2]}, 4]}]}, 4]}, {'Marginal_Adhesion <= 1': [{'Bare_Nuclei <= 1': [{'Mitoses = 3': [4, 2]}, {'Uniformity_of_Cell_Shape <= 3': [{'Single_Epithelial_Cell_Size = 3': [4, 2]}, 4]}]}, {'Uniformity_of_Cell_Size <= 4': [{'Marginal_Adhesion <= 6': [{'Bare_Nuclei <= 1': [2, 4]}, 4]}, 4]}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(*algo1.myfor,sep='\\nTrees\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as pt\n",
    "import pandas as pd\n",
    "\n",
    "def shffle_dta(ft, tar, sed=None):\n",
    "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
    "    if sed:\n",
    "        np.random.seed(sed)\n",
    "    id_ft = np.arange(ft.shape[0])\n",
    "    np.random.shuffle(id_ft)\n",
    "    return ft[id_ft], tar[id_ft]\n",
    "\n",
    "def trval_tsval_splt(ft, tar, tst_sze=0.5, shffle=True, sed=None):\n",
    "    \"\"\" Split the data into train and test sets \"\"\"\n",
    "    if shffle:\n",
    "        ft, tar = shffle_dta(ft, tar, sed)\n",
    "    # Split the training data from test data in the ratio specified in\n",
    "    # test_size\n",
    "    splt_i = len(tar) - int(len(tar) // (1 / tst_sze))\n",
    "    ft_trval, ft_tsval = ft[:splt_i], ft[splt_i:]\n",
    "    tar_trval, tar_tsval = tar[:splt_i], tar[splt_i:]\n",
    "\n",
    "    return ft_trval, ft_tsval, tar_trval, tar_tsval\n",
    "\n",
    "def ac_scr(y_tr, y_pd):\n",
    "    acc = np.sum(y_tr == y_pd, axis=0) / len(y_tr)\n",
    "    return acc\n",
    "\n",
    "class Dec_Stmp():\n",
    "    def __init__(sf):\n",
    "        sf.polrty = 1\n",
    "        sf.f_ind = None\n",
    "        sf.thshld = None\n",
    "        sf.alpha = None\n",
    "\n",
    "class AdaBst():\n",
    "    def __init__(sf, n_cllf=5):\n",
    "        sf.n_cllf = n_cllf\n",
    "\n",
    "    def fit(sf, X, y):\n",
    "        n_smpls, n_fters = np.shape(X)\n",
    "        wt = np.full(n_smpls, (1 / n_smpls))\n",
    "        sf.cllfs = []\n",
    "        for _ in range(sf.n_cllf):\n",
    "            cllf = Dec_Stmp()\n",
    "            m_err = float('inf')\n",
    "            for f_i in range(n_fters):\n",
    "                f_vals = np.expand_dims(X[:, f_i], axis=1)\n",
    "                u_vals = np.unique(f_vals)\n",
    "                for thrshld in u_vals:\n",
    "                    pv = 1\n",
    "                    pred = np.ones(np.shape(y))\n",
    "                    pred[X[:, f_i] < thrshld] = -1\n",
    "                    err = sum(wt[y != pred])\n",
    "                    if err > 0.5:\n",
    "                        err = 1 - err\n",
    "                        pv = -1\n",
    "                        if err < m_err:\n",
    "                            cllf.polarity = pv\n",
    "                            cllf.thrshld = thrshld\n",
    "                            cllf.f_index = f_i\n",
    "                            m_err = err\n",
    "            cllf.alpha = 0.5 * math.log((1.0 - m_err) / (m_err + 1e-10))\n",
    "            preds = np.ones(np.shape(y))\n",
    "            n_idx = (cllf.polarity * X[:, cllf.f_index] < cllf.polarity * cllf.thrshld)\n",
    "            preds[n_idx] = -1\n",
    "            wt *= np.exp(-cllf.alpha * y * preds)\n",
    "            wt /= np.sum(wt)\n",
    "            sf.cllfs.append(cllf)\n",
    "\n",
    "    def pred(sf, X):\n",
    "        n_smpls = np.shape(X)[0]\n",
    "        y_prd = np.zeros((n_smpls, 1))\n",
    "        print(sf.cllfs)\n",
    "        for cllf in sf.cllfs:\n",
    "            preds = np.ones(np.shape(y_prd))\n",
    "            n_idx = (cllf.polarity * X[:, cllf.f_index] < cllf.polarity * cllf.thrshld)\n",
    "            preds[n_idx] = -1\n",
    "            y_prd += cllf.alpha * preds\n",
    "        y_prd = np.sign(y_prd).flatten()\n",
    "        return y_prd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Dec_Stmp object at 0x000000123DAE59B0>, <__main__.Dec_Stmp object at 0x000000123B319908>, <__main__.Dec_Stmp object at 0x000000123B3190B8>, <__main__.Dec_Stmp object at 0x000000123B319E10>, <__main__.Dec_Stmp object at 0x000000123B319748>]\n",
      "Accuracy: 0.9330143540669856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  import sys\n",
      "C:\\Users\\amit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data')\n",
    "dt.columns=['Sample code number','Clump_Thickness','Uniformity_of_Cell_Size','Uniformity_of_Cell_Shape','Marginal_Adhesion','Single_Epithelial_Cell_Size','Bare_Nuclei','Bland_Chromatin','Normal_Nucleoli','Mitoses','label']\n",
    "dt=dt.replace('?',15)\n",
    "dt['Bare_Nuclei']=dt['Bare_Nuclei'].astype(dtype='i')\n",
    "dt.corr()['label']\n",
    "dt.dt=dt.iloc[:,1:-1].values\n",
    "dt.trgt=np.where(dt[\"label\"]==2,1,-1)\n",
    "\n",
    "feat = dt.dt\n",
    "tar = dt.trgt\n",
    "\n",
    "ft_trval, ft_tsval, tar_trval, tar_tsval = trval_tsval_splt(feat,tar,tst_sze=0.3)\n",
    "\n",
    "# Adaboost classification with 5 weak classifiers\n",
    "allgo = AdaBst(n_cllf=5)\n",
    "allgo.fit(ft_trval, tar_trval)\n",
    "tar_pred = allgo.pred(ft_tsval)\n",
    "\n",
    "accuracy = ac_scr(tar_tsval, tar_pred)\n",
    "print (\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as rt\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "dts=rt.request('get','https://archive.ics.uci.edu/ml/machine-learning-databases/00327/.old.arff')\n",
    "dts=arff.loadarff(StringIO(dts.text))\n",
    "data1=pd.DataFrame(dts[0])\n",
    "for col in data1.columns:\n",
    "    data1[col]=data1[col].astype(dtype='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xadc646b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data1.columns=list(data1.columns[:-1])+['label]\n",
    "sb.countplot(x='Result',data=data1)\n",
    "plt.savefig('f:/phsing_website_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = tr_te_split(data1, t_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
