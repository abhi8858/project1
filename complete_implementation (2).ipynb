{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as r\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Treregr:\n",
    "    def deviation(sf,count, l, r): \n",
    "        return (r/count) - (l/count)**2\n",
    "\n",
    "    def __init__(sf, train_x, train_y, indexes, depth=5):\n",
    "        sf.dx = train_x\n",
    "        sf.dy = train_y\n",
    "        sf.indexes = indexes\n",
    "        sf.depth = depth\n",
    "        sf.length = len(indexes)\n",
    "        sf.c = train_x.shape[1]\n",
    "        sf.val = np.mean(train_y[indexes])\n",
    "        sf.scr = float('inf')\n",
    "        sf.v_split()\n",
    "    \n",
    "    def find_split(sf, column_indexes):\n",
    "        column = sf.dx.values[sf.indexes,column_indexes]\n",
    "        target= sf.dy[sf.indexes]\n",
    "        sorted_indexes = np.argsort(column)\n",
    "        sorted_target = target[sorted_indexes]\n",
    "        sorted_column = column[sorted_indexes]\n",
    "        target_count = sf.length \n",
    "        target_sum = sorted_target.sum()\n",
    "        target_sqr_sum= (sorted_target**2).sum()\n",
    "        column_count = 0\n",
    "        column_sum = 0.\n",
    "        column_sqr_sum = 0.\n",
    "\n",
    "        for i in range(sf.length-sf.depth-1):\n",
    "            indivisual_x = sorted_column[i]\n",
    "            indivisual_y = sorted_target[i]\n",
    "            column_count += 1\n",
    "            target_count -= 1\n",
    "            column_sum += indivisual_y\n",
    "            target_sum -= indivisual_y\n",
    "            column_sqr_sum += indivisual_y**2\n",
    "            target_sqr_sum -= indivisual_y**2\n",
    "            if i<sf.depth or indivisual_x==sorted_column[i+1]:\n",
    "                continue\n",
    "\n",
    "            column_deviation = sf.deviation(column_count, column_sum, column_sqr_sum)\n",
    "            target_deviation = sf.deviation(target_count, target_sum, target_sqr_sum)\n",
    "            current_score = column_deviation*column_count/sf.length + target_deviation*target_count/sf.length\n",
    "            if current_score<sf.scr: \n",
    "                sf.column_indexes = column_indexes\n",
    "                sf.scr = current_score\n",
    "                sf.best_split = indivisual_x  \n",
    "    def v_split(sf):\n",
    "        for i in range(sf.c): \n",
    "            sf.find_split(i)\n",
    "\n",
    "        if sf.scr == float('inf'): \n",
    "            return\n",
    "        column = sf.dx.values[sf.indexes,sf.column_indexes]\n",
    "        left = np.nonzero(column<=sf.best_split)[0]\n",
    "        right = np.nonzero(column>sf.best_split)[0]\n",
    "        sf.lhs = Treeregressor(sf.dx, sf.dy, sf.indexes[left])\n",
    "        sf.rhs = Treeregressor(sf.dx, sf.dy, sf.indexes[right])\n",
    "\n",
    "    def prd(sf, prd_x):\n",
    "        if sf.scr == float('inf'): \n",
    "            return sf.val\n",
    "        if prd_x[sf.column_indexes]<=sf.best_split:\n",
    "            node = sf.lhs \n",
    "        else:\n",
    "            node=sf.rhs\n",
    "        return node.prd(prd_x) \n",
    "\n",
    "    def predict(sf, test_x):\n",
    "        return np.array([sf.prd(row) for row in test_x])\n",
    "    def coeff_determination(sf,y,regy): #r2_score by hand\n",
    "        sery=sum((y-regy)**2)\n",
    "        semy=sum((y-np.mean(y))**2)\n",
    "        return 1-(sery/semy)\n",
    "    def score(sf,x_test,y_test):\n",
    "        return sf.coeff_determination(y_test,sf.predict(x_test)),np.mean( (y_test-sf.predict(x_test))**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DReg():\n",
    "    def __init__(sf, train_x, train_y,cols, col_indexes,indexes,depth=10, mleaf=5):\n",
    "        sf.dx=train_x\n",
    "        sf.dy=train_y\n",
    "        sf.indexes = indexes\n",
    "        sf.depth = depth\n",
    "        sf.min_leaf=mleaf\n",
    "        sf.col_indexes = col_indexes\n",
    "        sf.cols = cols\n",
    "        sf.length = len(indexes)\n",
    "        sf.c = train_x.shape[1]\n",
    "        sf.val = np.mean(train_y[indexes])\n",
    "        sf.scr = float('inf')\n",
    "        sf.v_split()\n",
    "    def deviation(sf,count, l, r): \n",
    "        return (r/count) - (l/count)**2   \n",
    "    def v_split(sf):\n",
    "        for i in range(sf.c): \n",
    "            sf.find_split(i)\n",
    "\n",
    "        if sf.scr == float('inf') or sf.depth <= 0: \n",
    "            return\n",
    "        column = sf.dx.values[sf.indexes,sf.column_indexes]\n",
    "        left = np.nonzero(column<=sf.best_split)[0]\n",
    "        right = np.nonzero(column>sf.best_split)[0]\n",
    "        lf_idxs = np.random.permutation(sf.dx.shape[1])[:sf.cols]\n",
    "        rf_idxs = np.random.permutation(sf.dx.shape[1])[:sf.cols]\n",
    "        sf.lhs = DReg(sf.dx, sf.dy,sf.cols, lf_idxs, sf.indexes[left],sf.depth-1, sf.min_leaf)\n",
    "        sf.rhs = DReg(sf.dx, sf.dy,sf.cols, lf_idxs, sf.indexes[right],sf.depth-1,sf.min_leaf)\n",
    "\n",
    "    def find_split(sf, column_indexes):\n",
    "        column = sf.dx.values[sf.indexes,column_indexes]\n",
    "        target= sf.dy[sf.indexes]\n",
    "        sorted_indexes = np.argsort(column)\n",
    "        sorted_target = target[sorted_indexes]\n",
    "        sorted_column = column[sorted_indexes]\n",
    "        target_count = sf.length \n",
    "        target_sum = sorted_target.sum()\n",
    "        target_sqr_sum= (sorted_target**2).sum()\n",
    "        column_count = 0\n",
    "        column_sum = 0.\n",
    "        column_sqr_sum = 0.\n",
    "\n",
    "        for i in range(sf.length-sf.depth-1):\n",
    "            indivisual_x = sorted_column[i]\n",
    "            indivisual_y = sorted_target[i]\n",
    "            column_count += 1\n",
    "            target_count -= 1\n",
    "            column_sum += indivisual_y\n",
    "            target_sum -= indivisual_y\n",
    "            column_sqr_sum += indivisual_y**2\n",
    "            target_sqr_sum -= indivisual_y**2\n",
    "            if i<sf.depth or indivisual_x==sorted_column[i+1]:\n",
    "                continue\n",
    "\n",
    "            column_deviation = sf.deviation(column_count, column_sum, column_sqr_sum)\n",
    "            target_deviation = sf.deviation(target_count, target_sum, target_sqr_sum)\n",
    "            current_score = column_deviation*column_count/sf.length + target_deviation*target_count/sf.length\n",
    "            if current_score<sf.scr: \n",
    "                sf.column_indexes = column_indexes\n",
    "                sf.scr = current_score\n",
    "                sf.best_split = indivisual_x  \n",
    "    \n",
    "    def prd(sf, prd_x):\n",
    "        if sf.scr == float('inf'): \n",
    "            return sf.val\n",
    "        if prd_x[sf.column_indexes]<=sf.best_split:\n",
    "            node = sf.lhs \n",
    "        else:\n",
    "            node=sf.rhs\n",
    "        return node.prd(prd_x) \n",
    "class RFregressor():\n",
    "    def __init__(sf, x_tr, y_tr, number_of_trees, cols, sm_size, depth=10, mleaf=5):\n",
    "        np.random.seed(12)\n",
    "        if cols == 'sq':\n",
    "            sf.sl_col = int(np.sqrt(x_tr.shape[1]))\n",
    "        elif select_type == 'log':\n",
    "            sf.cols = int(np.log2(x_tr.shape[1]))\n",
    "        else:\n",
    "            sf.sl_type = cols\n",
    "        sf.dx=x_tr\n",
    "        sf.dy=y_tr\n",
    "        sf.sm_size=sm_size\n",
    "        sf.depth=depth\n",
    "        sf.mleaf=mleaf \n",
    "        sf.trees = [sf.single_tree() for i in range(number_of_trees)]\n",
    "\n",
    "    def single_tree(sf):\n",
    "        indexes = np.random.permutation(len(sf.dy))[:sf.sm_size]\n",
    "        selected_cols = np.random.permutation(sf.dx.shape[1])[:sf.sl_col]\n",
    "        return DReg(sf.dx.iloc[indexes], sf.dy[indexes], sf.sl_col,selected_cols,np.arange(sf.sm_size),sf.depth,sf.mleaf)\n",
    "        \n",
    "    def predict(sf, test_x):\n",
    "        return np.array([np.mean([t.prd(np.array(row)) for t in sf.trees], axis=0) for row in test_x])\n",
    "    \n",
    "    def coeff_determination(sf,y,regy): #r2_score by hand\n",
    "        sery=sum((y-regy)**2)\n",
    "        semy=sum((y-np.mean(y))**2)\n",
    "        return 1-(sery/semy)\n",
    "    def score(sf,x_ts,y_ts):\n",
    "        return sf.coeff_determination(y_ts,sf.predict(x_ts)),np.mean( (y_ts-sf.predict(x_ts))**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GBReg:\n",
    "    def __init__(sf, n_estmors, lrning_rt, mx_dept):\n",
    "        sf.mx_dept = mx_dept\n",
    "        sf.n_estmors = n_estmors\n",
    "        sf.lrning_rt = lrning_rt\n",
    "\n",
    "    def fitt(sf, ft, tar,indexes):\n",
    "        sf.estmors = []\n",
    "        tar = tar.astype(np.float)\n",
    "        for i in range(sf.n_estmors):\n",
    "            tre = Treregr(ft,tar,indexes,depth = sf.mx_dept)\n",
    "            tar_predt = tre.predict(np.array(ft))\n",
    "            sf.estmors.append(tre)  \n",
    "            tar -= sf.lrning_rt * tar_predt\n",
    "        return sf\n",
    "            \n",
    "    def predt(sf, ft):\n",
    "        tar_predt = np.zeros(ft.shape[0])\n",
    "        for tre in sf.estmors:\n",
    "            tar_predt += sf.lrning_rt * tre.predict(ft)\n",
    "        return tar_predt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tr_te_split(dtf, t_size):\n",
    "    t_size = int(t_size * dtf.shape[0]) # calculating the testsize according to the length of data\n",
    "    indexes = dtf.index.tolist() # we will take the index of the data-frame to randomize\n",
    "    t_index = r.sample(population=indexes, k=t_size) #using the random randomizing the indexes\n",
    "    test_df = dtf.loc[t_index]   #seprating the random test_data based on the random indexes obtained from t_index\n",
    "    train_df = dtf.drop(t_index)  # in train data we need to remove the t_index as it is in the test data\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data',sep='\\t')\n",
    "data=([np.array(i.split()) for i in data.iloc[:,0]])\n",
    "data=pd.DataFrame(data)\n",
    "data.columns=['mpg','cylinders','displacement','horsepower','weight','acceleration','model_year','origin']\n",
    "data['horsepower']=data.replace('?',np.mean(list(map(float,data[data['horsepower']!='?']['horsepower']))))\n",
    "for c in data.columns:\n",
    "    data[c]=data[c].astype(dtype='f')\n",
    "train, test = tr_te_split(data, t_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9983273279341545, 0.08872181922197342)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo=Treregr(train.drop('mpg',axis=1),np.array(train['mpg']),np.arange(len(train['mpg'])))\n",
    "algo.score(test.drop('mpg',axis=1).values,test['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9980224083637041, 0.10489536076784134)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RFregressor( train.drop('mpg',axis=1),np.array(train['mpg']),10, 'sq',train['mpg'].shape[0] ,10,5)\n",
    "reg.score(test.drop('mpg',axis=1).values,test['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regrr = GBReg(n_estmors = 100, lrning_rt = 0.1, mx_dept = 6)\n",
    "regrr.fitt(tren.drop('mpg',axis=1),np.array(tren['mpg']),np.arange(len(tren['mpg'])))\n",
    "regrr_tar_predt = regrr.predt(np.array(tst.drop('mpg',axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
